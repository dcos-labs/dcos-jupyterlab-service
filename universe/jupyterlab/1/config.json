{
  "type": "object",
  "properties": {
    "service": {
      "type": "object",
      "id": "https://github.com/dcos/examples/tree/master/jupyterlab",
      "title": "Mesosphere Jupyter Service Configuration",
      "description": "Mesospere Jupyter Service Configuration Properties.",
      "properties": {
        "name": {
          "type": "string",
          "title": "Mesosphere Jupyter Service Name",
          "description": "Unique name for this DC/OS JupyterLab service instance.",
          "default": "/jupyter-notebook"
        },
        "cmd": {
          "type": "string",
          "title": "Mesosphere Jupyter Service Entrypoint",
          "description": "The shell command to use to launch the Mesosphere Jupyter Service.",
          "default": "/usr/local/bin/start.sh ${CONDA_DIR}/bin/jupyter lab --notebook-dir=\"${MESOS_SANDBOX}\""
        },
        "cpus": {
          "type": "number",
          "title": "Mesosphere Jupyter Service CPU Allocation",
          "description": "CPU shares to allocate to this DC/OS JupyterLab service instance.",
          "minimum": 1.0,
          "default": 2.0
        },
        "mem": {
          "type": "integer",
          "title": "Mesosphere Jupyter Service Memory Allocation",
          "description": "Memory to allocate to the service instance in MB.",
          "minimum": 4096,
          "default": 8192
        },
        "gpu_support": {
          "type": "object",
          "title": "Nvidia GPU Configuration",
          "description": "Nvidia GPU configuration for the JupyterLab Notebook.",
          "properties": {
            "enabled": {
              "title": "Enable Nvidia GPU Support?",
              "description": "Note: This requires that CUDA 9.0.176-compatible Nvidia drivers be installed on the DC/OS agents that have GPUs.",
              "type": "boolean",
              "default": false
            },
            "gpus": {
              "type": "integer",
              "title": "Mesosphere Jupyter Service Nvidia GPU Allocation",
              "description": "Number of Nvidia GPUs to allocate to the Mesosphere Jupyter Service.\nNote: GPU support has to be enabled.",
              "minimum": 0,
              "default": 0
            }
          }
        },
        "user": {
          "type": "string",
          "title": "Linux User (Process Execution Context)",
          "description": "The Linux user under which the JupyterLab Notebook will run.",
          "default": "nobody"
        },
        "service_account": {
          "type": "string",
          "title": "Mesosphere Jupyter Service Account",
          "description": "The DC/OS Service Account to use for service authentication, or empty to use the default.",
          "default": ""
        },
        "service_account_secret": {
          "type": "string",
          "title": "DC/OS Service Account Credential Secret Name",
          "description": "(Optional) Path to the Secret to access the Service Account Credentials to use for DC/OS Service Authentication. This should be left empty unless service authentication is needed.",
          "default": ""
        },
        "force_pull_image": {
          "type": "boolean",
          "title": "Force-Pull DC/OS JupyterLab Docker?",
          "description": "Always force a pull of the DC/OS JupyterLab Docker image?",
          "default": false
        }
      },
      "required": [
        "cpus",
        "mem"
      ]
    },
    "oidc": {
      "type": "object",
      "title": "OpenID Connect (OIDC) Configuration",
      "description": "OpenID Connect Configuration.",
      "properties": {
        "enable_oidc": {
          "type": "boolean",
          "title": "Enable OpenID Connect Authentication for the Mesosphere Jupyter Service?",
          "description": "Enable OpenID Connect Authentication (and optional Authorization)?",
          "default": false
        },
        "oidc_discovery_uri": {
          "type": "string",
          "title": "OIDC Discovery URI",
          "description": "OpenID Connect Discovery URI.",
          "default": "https://keycloak.example.com/auth/realms/notebook/.well-known/openid-configuration"
        },
        "oidc_redirect_uri": {
          "type": "string",
          "title": "OIDC Redirect URI",
          "description": "OpenID Connect Redirect URI.",
          "default": "/oidc-redirect-callback"
        },
        "oidc_client_id": {
          "type": "string",
          "title": "OIDC Client ID",
          "description": "OpenID Connect Client ID.",
          "default": "notebook"
        },
        "oidc_client_secret": {
          "type": "string",
          "title": "OIDC Client Secret",
          "description": "OpenID Connect Client Secret.",
          "default": "b874f6e9-8f3f-41a6-a206-53e928d24fb1"
        },
        "oidc_tls_verify": {
          "type": "boolean",
          "title": "OIDC TLS Verify?",
          "description": "Verify TLS Certificates presented by the OpenID Connect endpoint?",
          "default": false
        },
        "oidc_authorized_email": {
          "type": "string",
          "title": "Email Address to Authorize",
          "description": "(Optional) E-Mail Address to be authorized (e.g., user@example.com), once authenticated.",
          "default": ""
        },
        "oidc_authorized_upn": {
          "type": "string",
          "title": "User Principal Name (UPN) to Authorize",
          "description": "(Optional) Windows Active Directory Federation Services UPN to be authorized (e.g., user007), once authenticated.",
          "default": ""
        },
        "oidc_logout_path": {
          "type": "string",
          "title": "OIDC Logout Path",
          "description": "OpenID Connect Logout Path.",
          "default": "/logmeout"
        },
        "oidc_use_spartan_resolver": {
          "type": "boolean",
          "title": "OIDC: Use DC/OS Highly Available DNS Dispatcher?",
          "description": "Use the DC/OS DNS Dispatcher (Spartan) to resolve OpenID Connect endpoints",
          "default": true
        }
      }
    },
    "spark": {
      "type": "object",
      "id": "https://spark.apache.org/docs/latest/configuration.html",
      "title": "Apache Spark Configuration",
      "description": "Apache Spark Configuration.",
      "properties": {
        "spark_master_url": {
          "type": "string",
          "title": "spark.master",
          "description": "The cluster manager (--master) to connect to.",
          "default": "mesos://zk://zk-1.zk:2181,zk-2.zk:2181,zk-3.zk:2181,zk-4.zk:2181,zk-5.zk:2181/mesos"
        },
        "spark_conf_cores_max": {
          "title": "spark.cores.max",
          "description": "The maximum amount of CPU cores to request for the application from across the cluster.",
          "type": "integer",
          "minimum": "1",
          "default": "5"
        },
        "spark_driver_cores": {
          "type": "integer",
          "title": "spark.driver.cores",
          "description": "Number of cores (--driver-cores) to use for the driver process.",
          "minimum": 1,
          "default": 2
        },
        "spark_conf_executor_cores": {
          "title": "spark.executor.cores",
          "description": "The number of cores to use on each executor.",
          "type": "integer",
          "minimum": "1",
          "default": "1"
        },
        "spark_driver_memory": {
          "type": "string",
          "title": "spark.driver.memory",
          "description": "Amount of memory (--driver-memory) to use for the driver process, i.e. where SparkContext is initialized, in MiB unless otherwise specified (e.g. 1g, 2g).",
          "default": "6g"
        },
        "spark_conf_executor_memory": {
          "type": "string",
          "title": "spark.executor.memory",
          "description": "spark.executor.memory: Amount of memory to use per executor process, in MiB unless otherwise specified. (e.g. 2g, 8g).",
          "default": "6g"
        },
        "spark_conf_spark_scheduler_min_registered_resources_ratio": {
          "title": "spark.scheduler.minRegisteredResourcesRatio",
          "description": "The minimum ratio of registered resources.",
          "type": "number",
          "minimum": "0.0",
          "maximum": "1.0",
          "default": "1.0"
        },
        "spark_driver_java_options": {
          "type": "string",
          "title": "spark.driver.extraJavaOptions",
          "description": "A string of extra JVM options (--driver-java-options) to pass to the driver.",
          "default": "'-server -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/mnt/mesos/sandbox'"
        },
        "spark_conf_executor_java_options": {
          "type": "string",
          "title": "spark.executor.extraJavaOptions",
          "description": "A string of extra JVM options to pass to executors.",
          "default": "'-server -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/mnt/mesos/sandbox'"
        },
        "spark_conf_eventlog_enabled": {
          "type": "boolean",
          "title": "spark.eventLog.enabled",
          "description": "Whether to log Spark events, useful for reconstructing the Web UI after the application has finished.",
          "default": false
        },
        "spark_conf_eventlog_dir": {
          "type": "string",
          "title": "spark.eventLog.dir",
          "description": "Base directory to which Spark events are logged, if spark.eventLog.enabled is true.",
          "default": "hdfs://hdfs/"
        },
        "spark_conf_hadoop_fs_s3a_aws_credentials_provider": {
          "type": "string",
          "enum":[
              "com.amazonaws.auth.InstanceProfileCredentialsProvider", 
              "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
          ],
          "title": "spark.hadoop.fs.s3a.aws.credentials.provider",
          "description": "Hadoop FS S3A Client Credentials Provider.",
          "default": "com.amazonaws.auth.InstanceProfileCredentialsProvider"
        },
        "spark_conf_jars_packages": {
          "type": "string",
          "title": "spark.jars.packages",
          "description": "Comma-separated list of Maven coordinates of jars to include on the driver and executor classpaths.",
          "default": "org.apache.spark:spark-streaming-kafka-0-10_2.11:2.2.1,org.apache.kafka:kafka_2.11:0.10.2.1"
        },
        "spark_conf_mesos_executor_docker_image": {
          "type": "string",
          "title": "spark.mesos.executor.docker.image",
          "description": "Set the name of the docker image that the Spark executors will run in.",
          "default": "dcoslabs/dcos-spark:1.11.4-2.2.1"
        },
        "spark_conf_mesos_executor_home": {
          "type": "string",
          "title": "spark.mesos.executor.home",
          "description": "Set the directory in which Spark is installed on the executors in Mesos.",
          "default": "/opt/spark"
        },
        "spark_conf_mesos_containerizer": {
          "type": "string",
          "enum": [
              "mesos",
              "docker"
          ],
          "id": "https://docs.mesosphere.com/1.11/deploying-services/containerizers/#container-runtime-features",
          "title": "spark.mesos.containerizer",
          "description": "Must be one of 'mesos' or 'docker'. Note: The Docker Containerizer does not support GPUs or File-Based Secrets",
          "default": "mesos"
        },
        "spark_conf_mesos_principal": {
          "description": "Spark Mesos Principal.",
          "type": "string",
          "default": ""
        },
        "spark_conf_mesos_role": {
          "description": "Spark Mesos Role.",
          "type": "string",
          "default": ""
        },
        "spark_conf_mesos_driver_labels": {
          "type": "string",
          "title": "spark.mesos.driver.labels",
          "description": "Mesos labels to add to the driver. Labels are free-form key-value pairs. Key-value pairs should be separated by a colon, and commas used to list more than one. If your label includes a colon or comma, you can escape it with a backslash. Ex. key:value,key2:a\:b.",
          "default": "DCOS_SPACE:"
        },
        "spark_conf_mesos_task_labels": {
          "type": "string",
          "title": "spark.mesos.task.labels",
          "description": "Set the Mesos labels to add to each task. Labels are free-form key-value pairs. Key-value pairs should be separated by a colon, and commas used to list more than one. If your label includes a colon or comma, you can escape it with a backslash. Ex. key:value,key2:a\:b.",
          "default": "DCOS_SPACE:"
        },
        "spark_conf_executor_krb5_config": {
          "type": "string",
          "title": "spark.executorEnv.KRB5_CONFIG",
          "description": "Location of the krb5.conf file passed via the KRB5_CONFIG environment variable to the Spark Executors.",
          "default": "/mnt/mesos/sandbox/krb5.conf"
        },
        "spark_conf_executor_java_home": {
          "type": "string",
          "title": "spark.executorEnv.JAVA_HOME",
          "description": "Location of the Java runtime passed via the JAVA_HOME environment variable to the Spark Executors.",
          "default": "/opt/jdk"
        },
        "spark_conf_executor_hadoop_hdfs_home": {
          "type": "string",
          "title": "spark.executorEnv.HADOOP_HDFS_HOME",
          "description": "Location of the Hadoop distribution passed via the HADOOP_HDFS_HOME environment variable to the Spark Executors.",
          "default": "/opt/hadoop"
        },
        "spark_conf_executor_hadoop_opts": {
          "type": "string",
          "title": "spark.executorEnv.HADOOP_OPTS",
          "description": "JVM Options to pass to the Hadoop runtime via the HADOOP_OPTS environment variable to the Spark Executors.",
          "default": "spark.executorEnv.HADOOP_OPTS='-Djava.library.path=/opt/hadoop/lib/native -Djava.security.krb5.conf=/mnt/mesos/sandbox/krb5.conf'"
        },
        "spark_conf_mesos_executor_docker_forcepullimage": {
          "type": "boolean",
          "title": "spark.mesos.executor.docker.forcePullImage",
          "description": "Force Mesos agents to pull the image specified in spark.mesos.executor.docker.image.",
          "default": false
        },
        "spark_user": {
          "type": "string",
          "title": "Spark User (Process Execution Context)",
          "description": "The Linux user under which the Spark Executors will run",
          "default": "nobody"
        },
        "start_spark_history_server": {
          "type": "boolean",
          "title": "Start Spark History Server?",
          "description": "Start Spark History Server.",
          "default": false
        },
        "spark_history_fs_logdirectory": {
          "type": "string",
          "title": "Spark EventLog Directory.",
          "description": "Spark EvenLog Directory from which to load events for prior Spark job runs.",
          "default": "hdfs://hdfs/"
        },
        "enable_spark_monitor": {
          "type": "boolean",
          "title": "Enable Spark Monitor?",
          "description": "Enable the Spark Monitor Jupyter Notebook Server Extension to proxy the Spark Driver UI?",
          "default": true
        }
      }
    },
    "storage": {
      "type": "object",
      "title": "Mesosphere Jupyter Service Storage Configuration.",
      "description": "Mesosphere Jupyter Service Storage Configuration.",
      "properties": {
        "s3": {
          "type": "object",
          "title": "S3 Object Store Configuration",
          "description": "S3 Object Store Configuration.",
          "properties": {
            "aws_region": {
              "type": "string",
              "title": "S3: Region",
              "description": "S3 Region.",
              "default": "us-east-1"
            },
            "s3_endpoint": {
              "type": "string",
              "title": "S3: Endpoint",
              "description": "S3 Endpoint.",
              "default": "s3.us-east-1.amazonaws.com"
            },
            "s3_https": {
              "type": "boolean",
              "title": "S3: Enable HTTPS?",
              "description": "Enable connections to S3 over HTTPS?",
              "default": true
            },
            "s3_ssl": {
              "type": "boolean",
              "title": "S3: Verify TLS?",
              "description": "Verify TLS Certificate(s) for the S3 endpoint?",
              "default": true
            }
          }
        },
        "persistence": {
          "type": "object",
          "title": "Local Persistent Storage Configuration",
          "description": "Local Persistent Storage Configuration.",
          "properties": {
            "host_volume_size": {
              "title": "Persistent Volume Size",
              "description": "Size of the local persistent volume in MiB.",
              "type": "integer",
              "default": 4000
            },
            "enable": {
              "title": "Enable Local Persistent Storage?",
              "description": "Enable or disable persistent storage.",
              "type": "boolean",
              "default": false
            }
          }
        }
      }
    },
    "networking": {
      "type": "object",
      "title": "DC/OS JupyterLab Networking Configuration",
      "description": "DC/OS JupyterLab Networking Configuration.",
      "properties": {
        "cni_support": {
          "type": "object",
          "description": "Enable Container Networking Interface (CNI) Support.",
          "properties": {
            "enabled": {
              "description": "Enable CNI support for this JupyterLab instance.",
              "type": "boolean",
              "default": true
            }
          }
        },
        "external_access": {
          "type": "object",
          "description": "Enable access from outside the cluster through Marathon-LB.\nNOTE: this connection is unencrypted.",
          "properties": {
            "enabled": {
              "description": "Enable or disable external access through a public node via Marathon-LB.",
              "type": "boolean",
              "default": true
            },
            "external_public_agent_hostname": {
              "description": "For external access, DNS to be used for Marathon-LB vHost: For example use your public slave ELB DNS.",
              "type": "string",
              "default": ""
            }
          }
        }
      }
    },
    "environment": {
      "type": "object",
      "description": "Additional Configuration Options.\n\nE.g. setting a JupyterLab password, overwriting the TensorBoard log directory.",
      "properties": {
        "conda_envs_path": {
          "description": "Conda Environments Path.",
          "type": "string",
          "default": "/mnt/mesos/sandbox/conda/envs:/opt/conda/envs"
        },
        "conda_pkgs_dir": {
          "description": "Conda Packages Directories.",
          "type": "string",
          "default": "/mnt/mesos/sandbox/conda/pkgs:/opt/conda/pkgs"
        },
        "dcos_dir": {
          "description": "DC/OS CLI Config Directory.",
          "type": "string",
          "default": "/mnt/mesos/sandbox/.dcos"
        },
        "hadoop_conf_dir": {
          "description": "Hadoop Configuration Directory.",
          "type": "string",
          "default": "/mnt/mesos/sandbox"
        },
        "home": {
          "description": "Your Home Directory.",
          "type": "string",
          "default": "/mnt/mesos/sandbox"
        },
        "java_opts": {
          "description": "Java Options.",
          "type": "string",
          "default": "'-server -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/mnt/mesos/sandbox'"
        },
        "jupyter_conf_urls": {
          "description": "Jupyter Configuration URLs as comma seperated list of URLs.",
          "type": "string",
          "default": ""
        },
        "jupyter_config_dir": {
          "description": "Jupyter Configuration Directory.",
          "type": "string",
          "default": "/mnt/mesos/sandbox/.jupyter"
        },
        "jupyter_password": {
          "description": "Jupyter Password.\n\nIf empty it defaults to password: \"jupyter\"",
          "type": "string",
          "default": ""
        },
        "jupyter_runtime_dir": {
          "description": "Jupyter Runtime Directory.",
          "type": "string",
          "default": "/mnt/mesos/sandbox/.local/share/jupyter/runtime"
        },
        "nginx_log_level": {
          "description": "NGINX log level.",
          "type": "string",
          "default": "warn"
        },
        "start_dask_distributed": {
          "description": "Start Dask distributed.",
          "type": "boolean",
          "default": false
        },
        "start_ray_head_node": {
          "description": "Start Ray Head Node.",
          "type": "boolean",
          "default": false
        },
        "start_tensorboard": {
          "description": "Start TensorBoard.",
          "type": "boolean",
          "default": false
        },
        "tensorboard_logdir": {
          "description": "TensorBoard Log Dir.",
          "type": "string",
          "default": "hdfs://hdfs/"
        },
        "term": {
          "description": "Unix Terminal Type.",
          "type": "string",
          "default": "xterm-256color"
        }
      }
    }
  }
}
